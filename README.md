# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
The data is about direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls to find out whether bank term deposit would be subscribed or not subscribed.

The best performing model found out using Azure's AutoML was VotingEnsemble classifier. With Azure's AutoML, we received an accuracy score of 0.9166 within just 5 iterations.

## Scikit-learn Pipeline
Steps in entry train.py:

1.TabularDataset creation using TabularDatasetFactory.
2.Data cleaning 
3.Splitting the data into train and test sets.
4.Training the logistic regression model using arguments from the HyperDrive runs.
5.Calculating the accuracy score.

Steps involved in udacity-project.ipynb:

1.Assigning a compute cluster to be used as the target.
2.Specifying the parameter sampler(RandomParameterSampling).
3.Specifying an early termination policy(BanditPolicy).
4.Creating a SKLearn estimator for use with train.py.
5.Creating a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.
6.Submitting the hyperdrive run to the experiment and showing run details.
7.Getting the best run id and saving the model.
8.Saving the model under the workspace for deployment.

**What are the benefits of the parameter sampler you chose?**
Parameter sampling means to search the hyperparameter space defined for your model and select the best values of a particular hyperparameter. In random sampling, hyperparameter values are chosen randomly . 

**What are the benefits of the early stopping policy you chose?**
An early termination policy ensures that we don't keep running the experiment for too long and end up wasting resources and time, in order to find the optimal parameter. A run is cancelled when the criteria of a specified policy are met. In our project we have used BanditPolicy as the early termination policy.This early termination policy is based on the slack factor and delay evaluation. 

## AutoML
**Description of the model and hyperparameters generated by AutoML:**
Since it was a classifiaction task, the primary metric that was to be maximized was set to 'accuracy'. We provided the cleaned version of the data. The model was trained remotely on the compute cluster created initially. The model that gave the best results turned out to be VotingEnsembleClassifier that takes the average of the predictions of the base models. It gave as an accuracy score of 0.9166 which was slightly better than the score achieved using HyperDrive.

## Pipeline comparison
**Comparison between the two models and their performance:**
Model trained using AutoML gave slightly better results. The AutoML model gave best accuracy of 0.9166(with VotingEnsembleClassifier), while the model built using SKLearn and HyperDrive gave a slightly lower score of 0.9072. The SKlearn model was iterated 20 times, while the AutoML model was iterated only 5 times(due to time limits). If the number of entries in the dataset is large, this could be a differentiating factor. Apart from that, an entry script was not a part of the architecture of the AutoML config.

## Future work
Implementation of feature engineering can be a potential field for future work. We can also tune some other hyperparameters used in the model and use the pipelines suggested by the AutoML models in order to achieve better results in the future. 
